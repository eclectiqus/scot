Federation cases

site scot (Sscot) to COE scot (Cscot) communication can be logically two way:

Cscot to Sscot
    #1: stuff created in Cscot pushed to a site scot

Sscot to Cscot
    #2: stuff created in site gets push to Cscot
    #3: Sscot can query Cscot for data

Use cases:

1.  Site SCOT creates new data and is eligible for sharing.

    * ScottyUp performs a REST POST of data to Upstream SCOTs.

2.  Site SCOT unshares a piece of data.

    * SCottyUp performs a REST DELETE of that Data on Upstream SCOTs.

3.  Site SCOT updated data that has been shared.

    * ScottyUp performs a REST PUT of the data to the Upstream SCOTs

4.  Upstream SCOT wishes to "Push" data into a site SCOT.

    * ScottyDown polls AMQ topic for notification that data is available for push.
      One message received, ScottyDown performs a REST GET of data, and then creates 
      Data as local.  

5.  Site SCOT whats federated Entity data for "flair".
   
    * As flair data is being queried, a secondary query to Upstream SCOT is performed.
      returned data is then merged and returned to client.



Configuration:

    * Scotty Up

        - upstream server(s?) data
        - sharing strategy
            . explicit share = only when an analyst marks something as share
            . share most     = after configurable timeout, assume data is sharable
            . share all      = all data is shareable

            Question: intersection of TLP and sharing... how to handle?

        - Deletes and Updates happen immediately on previously shared objects.
        
        - share entity as seperate strategy?

    * Scotty Down

        - proxy config
        - comet polling timeout
        - username


Multi-level (Network)  or Single Hub and spoke

    * Network
        - increased complexity
        + scalability

    * single hub
        + easy
        - potential scalability issues

Data replication vs. Federation

    * replications (to hub)
        + resilient to network troubles
        + easy implementation
        - data divergence during partition
        

    * federation
        + single copy of data, no divergence from truth
        - network access issues
        - must keep track of location of data 
        
