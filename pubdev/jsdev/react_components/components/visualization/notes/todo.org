* TODO Save useful commands/scripts (In progress)
  Users should be able to save and parameterize sequences of commands
  they like. Saved scripts should be publishable to the server with a
  tag to indicate which user owns it and whether it is public or not.

  The command should then be invoked by typing its alias on the prompt
  along with any arguments it needs.
  
** Design
    Users can create a script, which is a sequence of commands, a set
    of parameters, and a documentation string. The script will be
    saved in localstorage, and if the user requests it, uploaded to
    the server using the signature api.
    
    Scripts have their own namespace in the shell, which is checked
    after the default command set (scripts will not override built-in
    commands - I can argue either side on this so it might need to be
    changed). When a script is invoked, a new context is pushed onto
    the context stack. The context will automatically check parent
    levels in the event that the script tries to access global data.
*** DONE Copy on write
    If the script modifies a global value, the context will use a
    copy-on-write operation to keep the changes local to the script's
    context. This might need to be configurable, but initially keeping
    changes local seems safer.

    This is working, as long as it's only applied to the top level. If
    you change a subfield of a global object, the global object will
    be changed. If you redefine a name in the namespace though, it
    will be preserved. 
*** Editor
    Creating a command script will require a special editor because
    the environment would become polluted with old data and error
    commands if the base command prompt was used.

    The editor needs to allow a series of commands to be edited as a
    group. It should also allow the user to execute the script as it
    is being developed by entering values for parameters and clicking
    a button. The editor should then push a new scope, set the
    parameter values as needed within the scope, paste the script into
    the shell, and execute it. Afterward the new scope should be
    popped and the shell returned to its original state. This should
    allow the user to test the script as it is being developed without
    polluting the environment and causing unexpected errors later.
*** Storage
    Scripts need to have a name, the command list, required
    parameters, and some documentation. A simple js object should
    suffice, which can be dumped into localstorage by simple
    stringification.

    A notional format for script storage would be:
#+begin_src javascript
  {
    name: "name_of_command",
    help: "documentation as a string",
    params: ["list","of","parameter","names"],
    code: ["list","of","commands"]
  }
#+end_src
*** Upload
    After scripts can be stored locally, I want to be able to push
    them to the server for sharing. The tricky part of this will be to
    allow the user to decide when a script should be pulled down from
    the server for use locally, and potentially to control access for
    private scripts.

    My first thought here is to make 'collections' of scripts on the
    server, where a collection is basically a name space. Each user
    will have a default collection under their username, and can
    choose to import scripts from other collections via some kind of
    UI feature or command (e.g. import user/ejlee at the command line
    to import all scripts with the 'user/ejlee' collection name).

* TODO Server-side default analysis pipelines
  We want to be able to have everything but the rendering done by the
  server for some pipelines that are just useful all the time. The
  data that finally makes it to the visualization would then be cached
  and linked to the stuff it visualizes so that the browser can pull
  it down and display it immediately when requested.

  I could have an amq listener running that takes new data from SCOT
  and generates and uploads the viz stuff as embellishments. This
  would require an amq connection from nodejs on the server, and
  permission for the nodejs process to upload to SCOT (maybe a special
  login or something).

* TODO Unify graphics format and make it pipeable
  It would be great if there was one simple data structure that
  represented the graphics for the visualizations, or at least if
  there was a simple uniform-feeling way to specify all of the
  visualizations. Something list-based would be ideal, but in order to
  have relevant drill-down data attached it'll be necessary to add
  named fields.

  I could make an algebraic data type approximation that has a library
  of basic shapes, and set it up so that any entity can have both a
  shape and an associated data object. Interacting with the shape in
  the viz would then use the data from the associated object to
  control the interaction.
#+BEGIN_SRC haskell
data Param  ::  {color :: String,data :: String,label :: String}
data Graphic  ::  
   Polygon of {verts ::  Vec of Coord,assoc :: Param}
   Circle of {radius :: Float,center :: Coord,assoc :: Param}
   Rect of {ll :: Coord,ur :: Coord,assoc :: Param}
   Line of {p1 :: Coord,p2 :: Coord,assoc :: Param}
#+END_SRC

** Charts are a problem
   Charts are one of the key visualization tools, but they don't lend
   themselves well to pipeline operations as graphics. Charts instead
   need to be rendered based on their data points, and shouldn't exist
   as primitive graphic types.

   What would be nice is to figure out a uniform way to represent
   charts so that the same data format could be dropped into any of
   the basic chart types. Once the user makes chartable data, they
   should be able to view it in (almost?) any chart format.

   Charts also should support streaming updates when the iterator stuf
   lands.

*** Possible data format
    [{name: string, y: number x?: number, data?:{}, children?: [],<special keys>...},...]

    A list of data points. The x coordinate is optional. If it's not
    present the index of the item in the list will be used. The y
    coordinate is taken to be the value of the data point. The name is
    used to give labels when appropriate (either default on or
    mouseover). The data value is optionally used to support
    drill-down (the user clicks a bar in the chart and sees the list
    of things that made it for example). Finally, special keys can be
    added to let the user customize other parts of the visualization
    of that item (examples: color,shape,position,border).

    Creating a barchart would look like this:
#+BEGIN_SRC
    $ event limit:500,columns:['owner'],sort:{'id',-1} \ 
        group (e)->e.id \
        (evts,name)->{name:name,y:evts.length(),data:evts} \
        tolist \
        barchart
#+END_SRC 

    The last step (barchart) could be replaced by any other chart
    format. It could also be used as the data input for a voronoi
    diagram, which might have an outer cell for each user, with an
    inner cell for each event the user owns. In that case, the y
    parameter would be unnecessary unless it's used as a size hint for
    the voronoi cell.

*** Making it universal
    There are three basic kinds of data relationships that make this
    complicated:
    1. unrelated collections (data points)
    2. child relations (subtrees)
    3. network connections (peers)

    If I want a universal format, it needs to handle all of those
    basic kinds of data gracefully. It might be possible to do this as
    a "layers of data" kind of approach, where the basic collection is
    the core data format, and layers can be added to it to make child
    relationships and network relationships apparent. 

    Child relationships could be directly encoded in the structure of
    the data sample, so that each element has an optional 'children'
    member which is itself another data sample. Child relationships
    would be restricted by this structure so that something could only
    be a child of one other thing without a lot of headache. The
    connection scheme below might subsume this and give more
    flexibility.

    Connections could be represented as a list of pairs of names (or
    indexes into the original data array). That would enable the
    creation of graphs, and it could also be used to create flexible
    parent/child relationships that support many-to-many. If using
    this for parent/child relationships, it help if the user could
    specify what the "top" is without a lot of effort. It might just
    be as simple as specifying that a node is on the top if it's first
    in the first connection that includes it. 

** Bloat management
   Having the user attach data to graphics items could lead to
   dramatic bloat in the memory use (think an array of 1000 events,
   and hundreds of cells that each have a subset of that array within
   them). It might be necessary to implement a lazy access setup so
   that the user can delay the creation of the data for a given entity
   until it's actually needed by the viz. They would basically put a
   closure in the data slot that would be called when the data is
   needed. It could be release after the view closes. Alternatively, I
   could implement an iterator system like the one in rust that has
   map/filter/fold semantics. This would still require a closure from
   the user though, so there may not be much value to it.

   The closure approach is nice because all they would have to do
   would be to wrap whatever value they would have put in the data
   field in a thunk and the closure scope encapsulation will handle
   the rest. 

   This might interact badly with the streaming system unless I plan
   carefully to have the streaming iterator support forking (so that
   an iterator can be saved at some point and resumed from
   there). Forking could be done by just saving the data returned from
   next() starting with the first forked instance, and all subsequent
   insances would just point to the same saved data. Saved data would
   be shifted from the array as the earliest iterator fork progresses
   (earliest fork would have to be maintained because it may change
   over time). A forked iterator would only need to store a pointer to
   the original along with an index. If the index of the fork is equal
   to the original, it calls next on the original (and the original
   becomes the fork). 

   The user will have to know to use the right method of data access
   depending on the pipeline they have set up.
* TODO Storable intermediate non-POD type data
    User queries sometimes end up with data that's not just plain
    objects and arrays. When this data is stored it's converted to a
    string for localstorage, and when it's recovered it loses its
    associated class information (a Vector comes back as an object
    with {coords: [x,y]} but isn't usable as a Vector). I need to
    arrange some way of storing this stuff so that it comes back to
    life when it's restored.

    Best approach would probably to have a save method that leaves a
    hint about what type should be called to restore it.

* TODO Drill-down
  I need to make all of the viz stuff interactive. It would be a major
  win here if I had that unified viz format with interactive entities
  defined somehow. An algebraic data type would be great... 

  I want to be able to do things like click graph nodes to expand the
  network with more data, or drill into new levels of a treemap, or
  just click to see what the data is for a given entity.

* TODO Streaming implementation
  It would be great if the result monad could be modified to work like
  an iterator so that live data could be streamed through the app. I'm
  imagining a way to have a viz that shows a window of time as events
  stream through it. 

  To make this composable, I'd want to separate the model from the
  viz, and have a special accumulator that updates the model and sends
  it to the viz for rendering. As events stream through, the model
  accumulator would create, update, and destroy components of the viz,
  and the renderer would just display its current state at any given
  time. The user could control the behavior of the accumulator.

  The viz modules would then be modified to take an iterator, and to
  treat each item from the iterator as an updated model to
  render. They would add viz-computed annotations to the model to hold
  things that are only relevant for the rendering (node positions in a
  force-layout graph for example, or point coordinates for a voronoi
  diagram).

  Models should be structural, indicating only the relationships and
  generating data for the entities. The viz should have the power to
  actually turn that into graphics objects.

* TODO Interactivity
  Viz primitives need to support clicking, dragging, pan and zoom, and
  other interactions. Once again, this depends on having a consistent
  model for representing the viz parts.
