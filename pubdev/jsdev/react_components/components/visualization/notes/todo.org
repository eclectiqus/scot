* DONE Save useful commands/scripts (In progress)
  Users should be able to save and parameterize sequences of commands
  they like. Saved scripts should be publishable to the server with a
  tag to indicate which user owns it and whether it is public or not.

  The command should then be invoked by typing its alias on the prompt
  along with any arguments it needs.
  
** DONE Next step
   Save scripts to localstorage and restore them, then load them as
   commands into the shell. After that, upload to signature API and it
   will be ready.
** Design
    Users can create a script, which is a sequence of commands, a set
    of parameters, and a documentation string. The script will be
    saved in localstorage, and if the user requests it, uploaded to
    the server using the signature api.
    
    Scripts have their own namespace in the shell, which is checked
    after the default command set (scripts will not override built-in
    commands - I can argue either side on this so it might need to be
    changed). When a script is invoked, a new context is pushed onto
    the context stack. The context will automatically check parent
    levels in the event that the script tries to access global data.
*** DONE Copy on write
    If the script modifies a global value, the context will use a
    copy-on-write operation to keep the changes local to the script's
    context. This might need to be configurable, but initially keeping
    changes local seems safer.

    This is working, as long as it's only applied to the top level. If
    you change a subfield of a global object, the global object will
    be changed. If you redefine a name in the namespace though, it
    will be preserved. 
*** DONE Editor
    Creating a command script will require a special editor because
    the environment would become polluted with old data and error
    commands if the base command prompt was used.

    The editor needs to allow a series of commands to be edited as a
    group. It should also allow the user to execute the script as it
    is being developed by entering values for parameters and clicking
    a button. The editor should then push a new scope, set the
    parameter values as needed within the scope, paste the script into
    the shell, and execute it. Afterward the new scope should be
    popped and the shell returned to its original state. This should
    allow the user to test the script as it is being developed without
    polluting the environment and causing unexpected errors later.
*** DONE Storage
    Scripts need to have a name, the command list, required
    parameters, and some documentation. A simple js object should
    suffice, which can be dumped into localstorage by simple
    stringification.

    A notional format for script storage would be:
#+begin_src javascript
  {
    name: "name_of_command",
    help: "documentation as a string",
    params: ["list","of","parameter","names"],
    code: ["list","of","commands"]
  }
#+end_src
*** DONE Upload
    After scripts can be stored locally, I want to be able to push
    them to the server for sharing. The tricky part of this will be to
    allow the user to decide when a script should be pulled down from
    the server for use locally, and potentially to control access for
    private scripts.

    My first thought here is to make 'collections' of scripts on the
    server, where a collection is basically a name space. Each user
    will have a default collection under their username, and can
    choose to import scripts from other collections via some kind of
    UI feature or command (e.g. import user/ejlee at the command line
    to import all scripts with the 'user/ejlee' collection name).

*** Sharing
    Users should be able to import scripts from other users and keep
    them up to date.

* TODO Viz module uniform interface
  The visualization modules need to have a simple and consistent
  interface for letting the users interact with them. Some basic
  options that would be universally useful:
 
** Increment/Decrement detail
   Several tools have to decide what proportion of data to display,
   leaving some of it out. If there was a simple way for the user to
   tell it to increase the level of information being displayed, the
   user would be able to control how busy the picture was. For
   example, the chart viz tools could start out with no labels, then
   for level one they could display a substring of the label, and for
   level two they could display the full label.

** Filter visible elements
   It would be nice to be able to filter out or at least to
   deemphasize elements based on their data fields. A user might want
   to see labels only if they match a regex, or only display data
   points if they're greater than a threshold, etc. Filter conditions
   on what is being displayed would be useful. Each visualization
   would have its own set of things that can be filtered, and they
   should be settable via an auto-hide on-screen dialog that tells the
   user what fields are available along with their current values.

** Zoom and pan
   Every viz should support the ability to zoom in and pan around.

** Snapshot
   The viz should be able to recreate the exact view being displayed
   from a saved data structure. This is intended to make it easy to
   save particular views to the server, and to make them searchable
   (as opposed to saving an image screenshot).  The view should
   therefore be fully parametric, with the zoom/pan, filters, detail
   levels, etc. set in a datastructure that is just rendered by a dumb
   renderer. A view model that is drawn by a view-viewer and edited by
   a view-controller. The view controller could be a component that is
   shared by all views potentially. The view model would be everything
   needed to fully recreate the view, and it would be what the user
   generates using the data manipulation primitives.

** Subwindow views
   If the user could specify subwindows that have their own view
   models and viewers, it would allow things like picking an item in
   one view and seeing details about it in the subwindow view. The
   view should automatically support the subwindow functionality and
   allow the user to do something like right-click and send the data
   through a user-defined pipeline into the subview renderer.

** Selections
   If a view has discrete objects, they should be selectable. The
   selection should be represented in a way that can be operated on by
   the pipeline system - i.e. a list of entities that were used to
   generate the selected objects. That list (or maybe object) could
   then be sent to other views or saved and restored. Each
   view-renderer would be responsible for identifying the items that
   were selected, and the view controller would keep the list of
   selections as a data item in the view model.

* TODO Configuration to support multi-proxy setups
  One of the features that seems to get the attention of the IR guys
  more than anything else is the ability to access data from more than
  just the SCOT API. To do that, I need to have better support for
  proxying to different servers.

  The simplest way to get that started I think is to have a collection
  of API command groups, each of which is stashed under a descriptive
  root directory from the URL. Then the apache proxy would just split
  out the proxies based on that information and send data to
  appropriate servers as needed.

  To support that, I need to be able to tell REVL what the proxy root
  url configs are for each reachable API, which means I need a
  storable setting for each user that keeps track of their API
  endpoints and the urls associated with them. I also need a UI front
  end for managing that configuration (or at least a command to
  display the proxy settings and update the mappings - this is
  probably the right way actually).

* TODO Server-side default analysis pipelines
  We want to be able to have everything but the rendering done by the
  server for some pipelines that are just useful all the time. The
  data that finally makes it to the visualization would then be cached
  and linked to the stuff it visualizes so that the browser can pull
  it down and display it immediately when requested.

  I could have an amq listener running that takes new data from SCOT
  and generates and uploads the viz stuff as embellishments. This
  would require an amq connection from nodejs on the server, and
  permission for the nodejs process to upload to SCOT (maybe a special
  login or something).

* TODO Unify graphics format and make it pipeable
  It would be great if there was one simple data structure that
  represented the graphics for the visualizations, or at least if
  there was a simple uniform-feeling way to specify all of the
  visualizations. Something list-based would be ideal, but in order to
  have relevant drill-down data attached it'll be necessary to add
  named fields.

  I could make an algebraic data type approximation that has a library
  of basic shapes, and set it up so that any entity can have both a
  shape and an associated data object. Interacting with the shape in
  the viz would then use the data from the associated object to
  control the interaction.
#+BEGIN_SRC haskell
data Param  ::  {color :: String,data :: String,label :: String}
data Graphic  ::  
   Polygon of {verts ::  Vec of Coord,assoc :: Param}
   Circle of {radius :: Float,center :: Coord,assoc :: Param}
   Rect of {ll :: Coord,ur :: Coord,assoc :: Param}
   Line of {p1 :: Coord,p2 :: Coord,assoc :: Param}
#+END_SRC

** Charts are a problem
   Charts are one of the key visualization tools, but they don't lend
   themselves well to pipeline operations as graphics. Charts instead
   need to be rendered based on their data points, and shouldn't exist
   as primitive graphic types.

   What would be nice is to figure out a uniform way to represent
   charts so that the same data format could be dropped into any of
   the basic chart types. Once the user makes chartable data, they
   should be able to view it in (almost?) any chart format.

   Charts also should support streaming updates when the iterator stuf
   lands.

*** Possible data format
    [{name: string, y: number x?: number, data?:{}, children?: [],<special keys>...},...]

    A list of data points. The x coordinate is optional. If it's not
    present the index of the item in the list will be used. The y
    coordinate is taken to be the value of the data point. The name is
    used to give labels when appropriate (either default on or
    mouseover). The data value is optionally used to support
    drill-down (the user clicks a bar in the chart and sees the list
    of things that made it for example). Finally, special keys can be
    added to let the user customize other parts of the visualization
    of that item (examples: color,shape,position,border).

    Creating a barchart would look like this:
#+BEGIN_SRC
    $ event limit:500,columns:['owner'],sort:{'id',-1} \ 
        group (e)->e.id \
        (evts,name)->{name:name,y:evts.length(),data:evts} \
        tolist \
        barchart
#+END_SRC 

    The last step (barchart) could be replaced by any other chart
    format. It could also be used as the data input for a voronoi
    diagram, which might have an outer cell for each user, with an
    inner cell for each event the user owns. In that case, the y
    parameter would be unnecessary unless it's used as a size hint for
    the voronoi cell.

*** Making it universal
    There are three basic kinds of data relationships that make this
    complicated:
    1. unrelated collections (data points)
    2. child relations (subtrees)
    3. network connections (peers)

    If I want a universal format, it needs to handle all of those
    basic kinds of data gracefully. It might be possible to do this as
    a "layers of data" kind of approach, where the basic collection is
    the core data format, and layers can be added to it to make child
    relationships and network relationships apparent. 

    Child relationships could be directly encoded in the structure of
    the data sample, so that each element has an optional 'children'
    member which is itself another data sample. Child relationships
    would be restricted by this structure so that something could only
    be a child of one other thing without a lot of headache. The
    connection scheme below might subsume this and give more
    flexibility.

    Connections could be represented as a list of pairs of names (or
    indexes into the original data array). That would enable the
    creation of graphs, and it could also be used to create flexible
    parent/child relationships that support many-to-many. If using
    this for parent/child relationships, it help if the user could
    specify what the "top" is without a lot of effort. It might just
    be as simple as specifying that a node is on the top if it's first
    in the first connection that includes it. 

** Bloat management
   Having the user attach data to graphics items could lead to
   dramatic bloat in the memory use (think an array of 1000 events,
   and hundreds of cells that each have a subset of that array within
   them). It might be necessary to implement a lazy access setup so
   that the user can delay the creation of the data for a given entity
   until it's actually needed by the viz. They would basically put a
   closure in the data slot that would be called when the data is
   needed. It could be release after the view closes. Alternatively, I
   could implement an iterator system like the one in rust that has
   map/filter/fold semantics. This would still require a closure from
   the user though, so there may not be much value to it.

   The closure approach is nice because all they would have to do
   would be to wrap whatever value they would have put in the data
   field in a thunk and the closure scope encapsulation will handle
   the rest. 

   This might interact badly with the streaming system unless I plan
   carefully to have the streaming iterator support forking (so that
   an iterator can be saved at some point and resumed from
   there). Forking could be done by just saving the data returned from
   next() starting with the first forked instance, and all subsequent
   insances would just point to the same saved data. Saved data would
   be shifted from the array as the earliest iterator fork progresses
   (earliest fork would have to be maintained because it may change
   over time). A forked iterator would only need to store a pointer to
   the original along with an index. If the index of the fork is equal
   to the original, it calls next on the original (and the original
   becomes the fork). 

   The user will have to know to use the right method of data access
   depending on the pipeline they have set up.
* TODO Storable intermediate non-POD type data
    User queries sometimes end up with data that's not just plain
    objects and arrays. When this data is stored it's converted to a
    string for localstorage, and when it's recovered it loses its
    associated class information (a Vector comes back as an object
    with {coords: [x,y]} but isn't usable as a Vector). I need to
    arrange some way of storing this stuff so that it comes back to
    life when it's restored.

    Best approach would probably to have a save method that leaves a
    hint about what type should be called to restore it.

* TODO Drill-down
  I need to make all of the viz stuff interactive. It would be a major
  win here if I had that unified viz format with interactive entities
  defined somehow. An algebraic data type would be great... 

  I want to be able to do things like click graph nodes to expand the
  network with more data, or drill into new levels of a treemap, or
  just click to see what the data is for a given entity.

* TODO Streaming implementation
  It would be great if the result monad could be modified to work like
  an iterator so that live data could be streamed through the app. I'm
  imagining a way to have a viz that shows a window of time as events
  stream through it. 

  To make this composable, I'd want to separate the model from the
  viz, and have a special accumulator that updates the model and sends
  it to the viz for rendering. As events stream through, the model
  accumulator would create, update, and destroy components of the viz,
  and the renderer would just display its current state at any given
  time. The user could control the behavior of the accumulator.

* TODO Interactivity
  Viz primitives need to support clicking, dragging, pan and zoom, and
  other interactions. Once again, this depends on having a consistent
  model for representing the viz parts.
